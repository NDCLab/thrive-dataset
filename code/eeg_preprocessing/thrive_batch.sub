#!/bin/bash
#SBATCH --job-name=MADE_pipeline         # create a short name for your job
#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --cpus-per-task=1
#SBATCH --time=24:00:00          # total run time limit (HH:MM:SS)
#SBATCH --mem=20G
#SBATCH --partition=highmem1
#SBATCH --qos=highmem1
#SBATCH --account=iacc_gbuzzell
#SBATCH --output=%x-%j.out

module load matlab-2021b

pwd; hostname; date
echo "flurm cpus per task: $SLURM_CPUS_PER_TASK"
printenv
#####SBATCH --mem=30G

### default memory is 8 GB
####SBATCH --job-name=Kia_thrive_MADE         # create a short name for your job
####SBATCH --mail-type=end          # send email when job ends
####SBATCH --mail-user=khoss005@fiu.edu

#matlab -nodisplay < MADE_pipeline_v1_0_thrive_01.m
dataset="thrive-dataset"
session="s1_r1"

sing_image="/home/data/NDClab/tools/instruments/containers/singularity/inst-container.simg"

#subjects_to_process=$(python3 subjects_yet_to_process.py $dataset $session)
#subjects_to_process=$(singularity exec $sing_image python3 subjects_yet_to_process.py $dataset $session) # use instruments container for pandas instead of miniconda
#subjects_to_process="3000012/3000015" #test
#subjects_to_process="3000021"
#subjects_to_process="3000022/3000023"
#subjects_to_process="3000011/3000015"
#subjects_to_process="3000005"
#subjects_to_process="3000006"
#subjects_to_process="3000026/3000028/3000030/3000031"
#subjects_to_process="3000026/3000028"
#subjects_to_process="3000030/3000031"
#subjects_to_process="3000030"
#subjects_to_process="3000031"
#subjects_to_process="3000033"
#subjects_to_process="3000033/3000034"
#subjects_to_process="3000039/3000041"
#subjects_to_process="3000044/3000045/3000046/3000047"
subjects_to_process="3000045"
#subjects_to_process="3000050"

#for subject in ${subjects_to_process}
#    do
#    matlab -nodisplay -nosplash -r "MADE_pipeline $dataset $subject $session"
#done
matlab -nodisplay -nosplash -r "MADE_pipeline $dataset $subjects_to_process $session"

#errors=$(cat ${SLURM_JOB_NAME}-${SLURM_JOB_ID}.out | grep "Error")
errors=$(cat ${SLURM_JOB_NAME}-${SLURM_JOB_ID}.out | grep "Error")
if [[ -z ${errors} ]]; then
    echo "EEG preprocessing on subjects $subjects_to_process complete."
else
    echo "EEG preprocessing on subjects $subjects_to_process exited with errors: ${errors}"
fi

singularity exec $sing_image python3 update-tracker-postMADE.py $dataset $session

echo "updated tracker"
